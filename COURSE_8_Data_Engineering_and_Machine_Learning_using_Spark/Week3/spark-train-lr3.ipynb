{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Train Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Logistic Regression classifier with Apache SparkML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "Starting installation...\n",
      "Please <<RESTART YOUR KERNEL>> (Kernel->Restart Kernel and Clear All Outputs)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export version=`python --version |awk '{print $2}' |awk -F\".\" '{print $1$2}'`\n",
    "\n",
    "echo $version\n",
    "\n",
    "if [ $version == '36' ] || [ $version == '37' ]; then\n",
    "    echo 'Starting installation...'\n",
    "    pip3 install pyspark==2.4.8 wget==3.2 pyspark2pmml==0.5.1 > install.log 2> install.log\n",
    "    if [ $? == 0 ]; then\n",
    "        echo 'Please <<RESTART YOUR KERNEL>> (Kernel->Restart Kernel and Clear All Outputs)'\n",
    "    else\n",
    "        echo 'Installation failed, please check log:'\n",
    "        cat install.log\n",
    "    fi\n",
    "elif [ $version == '38' ] || [ $version == '39' ]; then\n",
    "    pip3 install pyspark==3.1.2 wget==3.2 pyspark2pmml==0.5.1 > install.log 2> install.log\n",
    "    if [ $? == 0 ]; then\n",
    "        echo 'Please <<RESTART YOUR KERNEL>> (Kernel->Restart Kernel and Clear All Outputs)'\n",
    "    else\n",
    "        echo 'Installation failed, please check log:'\n",
    "        cat install.log\n",
    "    fi\n",
    "else\n",
    "    echo 'Currently only python 3.6, 3.7 , 3.8 and 3.9 are supported, in case you need a different version please open an issue at https://github.com/IBM/claimed/issues'\n",
    "    exit -1\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sitexv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "import os\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark2pmml import PMMLBuilder\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "import logging\n",
    "import shutil\n",
    "#import sitexv\n",
    "import sys\n",
    "import wget\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.version[0:3] == '3.9':\n",
    "    url = ('https://github.com/jpmml/jpmml-sparkml/releases/download/1.7.2/'\n",
    "           'jpmml-sparkml-executable-1.7.2.jar')\n",
    "    wget.download(url)\n",
    "    shutil.copy('jpmml-sparkml-executable-1.7.2.jar',\n",
    "                site.getsitepackages()[0] + '/pyspark/jars/')\n",
    "elif sys.version[0:3] == '3.8':\n",
    "    url = ('https://github.com/jpmml/jpmml-sparkml/releases/download/1.7.2/'\n",
    "           'jpmml-sparkml-executable-1.7.2.jar')\n",
    "    wget.download(url)\n",
    "    shutil.copy('jpmml-sparkml-executable-1.7.2.jar',\n",
    "                site.getsitepackages()[0] + '/pyspark/jars/')\n",
    "elif sys.version[0:3] == '3.7':\n",
    "    url = ('https://github.com/jpmml/jpmml-sparkml/releases/download/1.5.12/'\n",
    "           'jpmml-sparkml-executable-1.5.12.jar')\n",
    "    wget.download(url)\n",
    "elif sys.version[0:3] == '3.6':\n",
    "    url = ('https://github.com/jpmml/jpmml-sparkml/releases/download/1.5.12/'\n",
    "           'jpmml-sparkml-executable-1.5.12.jar')\n",
    "    wget.download(url)\n",
    "else:\n",
    "    raise Exception('Currently only python 3.6 , 3.7, 3,8 and 3.9 is supported, in case '\n",
    "                    'you need a different version please open an issue at '\n",
    "                    'https://github.com/IBM/claimed/issues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_parquet = os.environ.get('data_parquet',\n",
    "                              'data.parquet')  # input file name (parquet)\n",
    "master = os.environ.get('master',\n",
    "                        \"local[*]\")  # URL to Spark master\n",
    "model_target = os.environ.get('model_target',\n",
    "                              \"model.xml\")  # model output file name\n",
    "data_dir = os.environ.get('data_dir',\n",
    "                          '../../data/')  # temporary directory for data\n",
    "input_columns = os.environ.get('input_columns',\n",
    "                               '[\"x\", \"y\", \"z\"]')  # input columns to consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = list(\n",
    "    map(lambda s: re.sub('$', '\"', s),\n",
    "        map(\n",
    "            lambda s: s.replace('=', '=\"'),\n",
    "            filter(\n",
    "                lambda s: s.find('=') > -1 and bool(re.match(r'[A-Za-z0-9_]*=[.\\/A-Za-z0-9]*', s)),\n",
    "                sys.argv\n",
    "            )\n",
    "    )))\n",
    "\n",
    "for parameter in parameters:\n",
    "    logging.warning('Parameter: ' + parameter)\n",
    "    exec(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster(master)\n",
    "#if sys.version[0:3] == '3.6' or sys.version[0:3] == '3.7':\n",
    "conf.set(\"spark.jars\", 'jpmml-sparkml-executable-1.5.12.jar')\n",
    "\n",
    "sc = SparkContext.getOrCreate(conf)\n",
    "sqlContext = SQLContext(sc)\n",
    "spark = sqlContext.sparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(data_dir + data_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register a corresponding query table\n",
    "df.createOrReplaceTempView('df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "df = df.withColumn(\"x\", df.x.cast(DoubleType()))\n",
    "df = df.withColumn(\"y\", df.y.cast(DoubleType()))\n",
    "df = df.withColumn(\"z\", df.z.cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = df.randomSplit([0.8, 0.2])\n",
    "df_train = splits[0]\n",
    "df_test = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"class\", outputCol=\"label\")\n",
    "\n",
    "vectorAssembler = VectorAssembler(inputCols=eval(input_columns),\n",
    "                                  outputCol=\"features\")\n",
    "\n",
    "normalizer = MinMaxScaler(inputCol=\"features\", outputCol=\"features_norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|         class|count|\n",
      "+--------------+-----+\n",
      "| Use_telephone|15225|\n",
      "| Standup_chair|25417|\n",
      "|      Eat_meat|31236|\n",
      "|     Getup_bed|45801|\n",
      "|   Drink_glass|42792|\n",
      "|    Pour_water|41673|\n",
      "|     Comb_hair|23504|\n",
      "|          Walk|92254|\n",
      "|  Climb_stairs|40258|\n",
      "| Sitdown_chair|25036|\n",
      "|   Liedown_bed|11446|\n",
      "|Descend_stairs|15375|\n",
      "|   Brush_teeth|29829|\n",
      "|      Eat_soup| 6683|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select(\"class\").groupby(\"class\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[indexer, vectorAssembler, normalizer, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/18 08:42:02 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "21/12/18 08:42:02 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2066635477102284"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binEval = MulticlassClassificationEvaluator(). \\\n",
    "    setMetricName(\"accuracy\"). \\\n",
    "    setPredictionCol(\"prediction\"). \\\n",
    "    setLabelCol(\"label\")\n",
    "\n",
    "binEval.evaluate(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/resources/labs/BD0231EN/claimed/component-library/train/../../data/model.xml'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmmlBuilder = PMMLBuilder(sc, df_train, model)\n",
    "pmmlBuilder.buildFile(data_dir + model_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tester.ipynb',\n",
       " 'data.csv',\n",
       " 'model.xml',\n",
       " 'dummy',\n",
       " '.ipynb_checkpoints',\n",
       " 'data.parquet']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining hyperparameters values\n",
    "maxIter = [10, 100, 1000]\n",
    "regParam = [0.01, 0.5, 2.0]\n",
    "elasticNetParam = [0.0, 0.5, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty dictionary where hyperparameter and sccuracy combinations (27 in total) will be stored on every iteration\n",
    "dict_hyper = {\"maxIter\" : [], \"regParam\" : [], \"elasticNetParam\" : [], \"accuracy\" : []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination 1\n",
      "maxIter: 10\n",
      "regParam: 0.01\n",
      "elasticNetParam: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.3286640464913165\n",
      "\n",
      "\n",
      "Combination 2\n",
      "maxIter: 10\n",
      "regParam: 0.01\n",
      "elasticNetParam: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.333862407202123\n",
      "\n",
      "\n",
      "Combination 3\n",
      "maxIter: 10\n",
      "regParam: 0.01\n",
      "elasticNetParam: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.30973495918573013\n",
      "\n",
      "\n",
      "Combination 4\n",
      "maxIter: 10\n",
      "regParam: 0.5\n",
      "elasticNetParam: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.22246296482918473\n",
      "\n",
      "\n",
      "Combination 5\n",
      "maxIter: 10\n",
      "regParam: 0.5\n",
      "elasticNetParam: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.20686508336412598\n",
      "\n",
      "\n",
      "Combination 6\n",
      "maxIter: 10\n",
      "regParam: 0.5\n",
      "elasticNetParam: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.20686508336412598\n",
      "\n",
      "\n",
      "Combination 7\n",
      "maxIter: 10\n",
      "regParam: 2.0\n",
      "elasticNetParam: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.20686508336412598\n",
      "\n",
      "\n",
      "Combination 8\n",
      "maxIter: 10\n",
      "regParam: 2.0\n",
      "elasticNetParam: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.20686508336412598\n",
      "\n",
      "\n",
      "Combination 9\n",
      "maxIter: 10\n",
      "regParam: 2.0\n",
      "elasticNetParam: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.20686508336412598\n",
      "\n",
      "\n",
      "Combination 10\n",
      "maxIter: 100\n",
      "regParam: 0.01\n",
      "elasticNetParam: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.3466021700426618\n",
      "\n",
      "\n",
      "Combination 11\n",
      "maxIter: 100\n",
      "regParam: 0.01\n",
      "elasticNetParam: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.34431231594387895\n",
      "\n",
      "\n",
      "Combination 12\n",
      "maxIter: 100\n",
      "regParam: 0.01\n",
      "elasticNetParam: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.3451605137335259\n",
      "\n",
      "\n",
      "Combination 13\n",
      "maxIter: 100\n",
      "regParam: 0.5\n",
      "elasticNetParam: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.24064742965277078\n",
      "\n",
      "\n",
      "Combination 14\n",
      "maxIter: 100\n",
      "regParam: 0.5\n",
      "elasticNetParam: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.20686508336412598\n",
      "\n",
      "\n",
      "Combination 15\n",
      "maxIter: 100\n",
      "regParam: 0.5\n",
      "elasticNetParam: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.20686508336412598\n",
      "\n",
      "\n",
      "Combination 16\n",
      "maxIter: 100\n",
      "regParam: 2.0\n",
      "elasticNetParam: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.20686508336412598\n",
      "\n",
      "\n",
      "Combination 17\n",
      "maxIter: 100\n",
      "regParam: 2.0\n",
      "elasticNetParam: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.20686508336412598\n",
      "\n",
      "\n",
      "Combination 18\n",
      "maxIter: 100\n",
      "regParam: 2.0\n",
      "elasticNetParam: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.20686508336412598\n",
      "\n",
      "\n",
      "Combination 19\n",
      "maxIter: 1000\n",
      "regParam: 0.01\n",
      "elasticNetParam: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.34678132733156414\n",
      "\n",
      "\n",
      "Combination 20\n",
      "maxIter: 1000\n",
      "regParam: 0.01\n",
      "elasticNetParam: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.349552666644272\n",
      "\n",
      "\n",
      "Combination 21\n",
      "maxIter: 1000\n",
      "regParam: 0.01\n",
      "elasticNetParam: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/15 18:43:10 WARN storage.BlockManager: Asked to remove block broadcast_11341, which does not exist\n",
      "21/12/15 18:54:21 WARN storage.BlockManager: Asked to remove block broadcast_14554, which does not exist\n",
      "21/12/15 18:54:21 WARN storage.BlockManager: Asked to remove block broadcast_14554_piece0, which does not exist\n",
      "21/12/15 18:54:40 WARN storage.BlockManager: Asked to remove block broadcast_14647, which does not exist\n",
      "21/12/15 18:55:41 WARN storage.BlockManager: Asked to remove block broadcast_14938_piece0, which does not exist\n",
      "21/12/15 18:55:41 WARN storage.BlockManager: Asked to remove block broadcast_14938, which does not exist\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.352298811963228\n",
      "\n",
      "\n",
      "Combination 22\n",
      "maxIter: 1000\n",
      "regParam: 0.5\n",
      "elasticNetParam: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.24064742965277078\n",
      "\n",
      "\n",
      "Combination 23\n",
      "maxIter: 1000\n",
      "regParam: 0.5\n",
      "elasticNetParam: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.20686508336412598\n",
      "\n",
      "\n",
      "Combination 24\n",
      "maxIter: 1000\n",
      "regParam: 0.5\n",
      "elasticNetParam: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.20686508336412598\n",
      "\n",
      "\n",
      "Combination 25\n",
      "maxIter: 1000\n",
      "regParam: 2.0\n",
      "elasticNetParam: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.20686508336412598\n",
      "\n",
      "\n",
      "Combination 26\n",
      "maxIter: 1000\n",
      "regParam: 2.0\n",
      "elasticNetParam: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.20686508336412598\n",
      "\n",
      "\n",
      "Combination 27\n",
      "maxIter: 1000\n",
      "regParam: 2.0\n",
      "elasticNetParam: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11803:=============================================>       (12 + 2) / 14]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.20686508336412598\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "iteration = 1\n",
    "\n",
    "for i in maxIter:\n",
    "    for j in regParam:\n",
    "        for k in elasticNetParam:\n",
    "            \n",
    "            # Printing current hyperparameters values\n",
    "            print(\"Combination \" + str(iteration))\n",
    "            print(\"maxIter: \" + str(i))\n",
    "            print(\"regParam: \" + str(j))\n",
    "            print(\"elasticNetParam: \" + str(k))\n",
    "            \n",
    "            # Storing current hyperparameters values\n",
    "            dict_hyper[\"maxIter\"].append(i)\n",
    "            dict_hyper[\"regParam\"].append(j)\n",
    "            dict_hyper[\"elasticNetParam\"].append(k)\n",
    "            \n",
    "            # Defining model, pipeline and getting accuracy\n",
    "            lr = LogisticRegression(maxIter=i, regParam=j, elasticNetParam=k)\n",
    "            pipeline = Pipeline(stages=[indexer, vectorAssembler, normalizer, lr])\n",
    "            model = pipeline.fit(df_train)\n",
    "            prediction = model.transform(df_train)\n",
    "            binEval = MulticlassClassificationEvaluator(). \\\n",
    "                setMetricName(\"accuracy\"). \\\n",
    "                setPredictionCol(\"prediction\"). \\\n",
    "                setLabelCol(\"label\")\n",
    "            acc_temp = binEval.evaluate(prediction)\n",
    "            \n",
    "            # Appending accuracy result\n",
    "            dict_hyper[\"accuracy\"].append(acc_temp)\n",
    "            print(\"accuracy: \" + str(acc_temp))\n",
    "            iteration += 1\n",
    "            print()\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrame using pandas\n",
    "df2 = pd.DataFrame.from_dict(dict_hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting pandas DataFrame to spark DataFrame\n",
    "df2 = spark.createDataFrame(df2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------------+-------------------+\n",
      "|maxIter|regParam|elasticNetParam|           accuracy|\n",
      "+-------+--------+---------------+-------------------+\n",
      "|     10|    0.01|            0.0| 0.3286640464913165|\n",
      "|     10|    0.01|            0.5|  0.333862407202123|\n",
      "|     10|    0.01|            1.0|0.30973495918573013|\n",
      "|     10|     0.5|            0.0|0.22246296482918473|\n",
      "|     10|     0.5|            0.5|0.20686508336412598|\n",
      "|     10|     0.5|            1.0|0.20686508336412598|\n",
      "|     10|     2.0|            0.0|0.20686508336412598|\n",
      "|     10|     2.0|            0.5|0.20686508336412598|\n",
      "|     10|     2.0|            1.0|0.20686508336412598|\n",
      "|    100|    0.01|            0.0| 0.3466021700426618|\n",
      "|    100|    0.01|            0.5|0.34431231594387895|\n",
      "|    100|    0.01|            1.0| 0.3451605137335259|\n",
      "|    100|     0.5|            0.0|0.24064742965277078|\n",
      "|    100|     0.5|            0.5|0.20686508336412598|\n",
      "|    100|     0.5|            1.0|0.20686508336412598|\n",
      "|    100|     2.0|            0.0|0.20686508336412598|\n",
      "|    100|     2.0|            0.5|0.20686508336412598|\n",
      "|    100|     2.0|            1.0|0.20686508336412598|\n",
      "|   1000|    0.01|            0.0|0.34678132733156414|\n",
      "|   1000|    0.01|            0.5|  0.349552666644272|\n",
      "|   1000|    0.01|            1.0|  0.352298811963228|\n",
      "|   1000|     0.5|            0.0|0.24064742965277078|\n",
      "|   1000|     0.5|            0.5|0.20686508336412598|\n",
      "|   1000|     0.5|            1.0|0.20686508336412598|\n",
      "|   1000|     2.0|            0.0|0.20686508336412598|\n",
      "|   1000|     2.0|            0.5|0.20686508336412598|\n",
      "|   1000|     2.0|            1.0|0.20686508336412598|\n",
      "+-------+--------+---------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df2.show(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------------+-----------------+\n",
      "|maxIter|regParam|elasticNetParam|         accuracy|\n",
      "+-------+--------+---------------+-----------------+\n",
      "|   1000|    0.01|            1.0|0.352298811963228|\n",
      "+-------+--------+---------------+-----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.sort(desc('accuracy')).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resample Data Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 70:30 train:test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = df.randomSplit([0.7, 0.3], seed = 1)\n",
    "df_train = splits[0]\n",
    "df_test = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(maxIter=1000, regParam=0.01, elasticNetParam=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[indexer, vectorAssembler, normalizer, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.35272593945017283"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binEval = MulticlassClassificationEvaluator(). \\\n",
    "    setMetricName(\"accuracy\"). \\\n",
    "    setPredictionCol(\"prediction\"). \\\n",
    "    setLabelCol(\"label\")\n",
    "\n",
    "binEval.evaluate(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 90:10 train:test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = df.randomSplit([0.9, 0.1], seed = 1)\n",
    "df_train = splits[0]\n",
    "df_test = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(maxIter=1000, regParam=0.01, elasticNetParam=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[indexer, vectorAssembler, normalizer, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3525662454592053"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binEval = MulticlassClassificationEvaluator(). \\\n",
    "    setMetricName(\"accuracy\"). \\\n",
    "    setPredictionCol(\"prediction\"). \\\n",
    "    setLabelCol(\"label\")\n",
    "\n",
    "binEval.evaluate(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 55.042719,
   "end_time": "2021-01-28T16:00:26.871724",
   "environment_variables": {},
   "exception": null,
   "input_path": "/home/jovyan/work/elyra-classification/train-trusted-ai.ipynb",
   "output_path": "/home/jovyan/work/elyra-classification/train-trusted-ai.ipynb",
   "parameters": {},
   "start_time": "2021-01-28T15:59:31.829005",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
